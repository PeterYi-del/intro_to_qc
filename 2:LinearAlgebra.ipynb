{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 2:Linear Algebra\n",
    "\n",
    "### The first Station --- Linear Algebra\n",
    "Welcome! Please feel free to take a seat.  \n",
    "\n",
    "In this section, we will introduce some basic information about linear algebra. \n",
    " \n",
    "First, we have to admit that, all quantum computing are base on matrix, so matrix is absolute the most important things in quantum computing, we have to understand what is matrix first.  \n",
    "\n",
    "Second, we will introduce some notations and algorithms which will be used frequently in our later main body of quantum computing.  \n",
    "\n",
    "So sharpening the knife does not make you miss the woodwork, let's begin our adventure together.\n"
   ],
   "id": "d73ae8a2710d7e24"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### *2.1 Vector*\n",
    "Before we step into matrix, the biggest problem we have to face is------What makes up matrix?\n",
    "\n",
    "Some of you may say, you must be joking, all of us knows that numbers makes up matrix.\n",
    "  \n",
    "Woooo, take it easy, indeed numbers makes up matrix, that's true, but please think deeper, what if we divide the matrix into parts? You may already know the answer, a small matrix, that's right! You now warm up. But what if we divide it by rows and columns?  \n",
    "\n",
    "Yeah, you are right, the vectors! Congrats!"
   ],
   "id": "ff462299dc7c8c1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's start with a small example:",
   "id": "9c67bf203cb799b7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T14:15:20.383413Z",
     "start_time": "2024-06-03T14:15:20.176182Z"
    }
   },
   "cell_type": "code",
   "source": "import numpy as np",
   "id": "26d5f6f7710c113e",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T14:15:22.646755Z",
     "start_time": "2024-06-03T14:15:22.642933Z"
    }
   },
   "cell_type": "code",
   "source": [
    "a = np.array([[1,2,3]])\n",
    "print(\"a row vector:\\n\", a)\n",
    "b = a.transpose()\n",
    "print(\"b column vector:\\n\", b)"
   ],
   "id": "994b4ebdf2681697",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a row vector:\n",
      " [[1 2 3]]\n",
      "b column vector:\n",
      " [[1]\n",
      " [2]\n",
      " [3]]\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "You will see a vector contains three elements, *a* is called row vector, *b* is called column vector. The only different between *a* and *b* is the position of the elements.  \n",
    "\n",
    "In linear algebra, the concept of a vector has been abstracted, we are no longer limited to directions, we are transformed to think about more general states, and as you can see, a representation in the shape of $a(a1,a2,...,an)$ is a vector."
   ],
   "id": "c1f66775fb3dbb02"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### *2.2 Matrix*\n",
    "\n",
    "Well down, We got vectors!  \n",
    "\n",
    "The Next step, We combine the vectors, arranging them layer by layer like spreading jam, and in this way we get the most basic, and most important, element of quantum computing------the matrix\n",
    "\n",
    "You may have a little bit confused. How to describe a matrix?  \n",
    "\n",
    "Nice question! For example, the matrix below, which is c, has three blocks; each block has three numbers, so we call c the $3 \\times 3$ matrix. The first three represent how many rows in this matrix, and the second three represent haw many columns in this matrix.  \n",
    "\n",
    "So when you meet a matrix X, which is $m \\times n$, means X has m rows and n columns."
   ],
   "id": "429c9dcd597062af"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T14:15:26.326851Z",
     "start_time": "2024-06-03T14:15:26.322424Z"
    }
   },
   "cell_type": "code",
   "source": [
    "c = np.array([[1,2,3],[4,5,6],[7,8,9]])\n",
    "print(\"c the matrix:\\n\", c)"
   ],
   "id": "9cd72d736d809bb1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c the matrix:\n",
      " [[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### *2.3 Matrix Computing Methods*\n",
    "\n",
    "All right, we've made good friends with vectors and matrices, and the next thing we need to know is how these friends of ours do their calculations."
   ],
   "id": "ea5a2b8ae4f8589a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "##### *2.3.1 Matrix multiplication*\n",
    "\n",
    "In this section, we will meet some mathematics formulas, but don't worry, they won't hurt you. You got me. The first thing we need to understand is that how two matrixes do multiplication? You may say just like the real number. This is a good answer, but not correct. Indeed, some parts of multiplication can be described like real number, but not all of them. We use the formula below to calculate the multiplication of matrixes:  \n",
    "\n",
    "Prerequisite: A is a matrix which is $n \\times m$, B is another matrix which is $m \\times p$  \n",
    "\n",
    "The formula: $$C_i_j = a_i_1b_1_j + a_i_2b_2_j + ... + a_i_nb_n_j$$  \n",
    "$$= \\sum_{k = 1}^{n}a_i_kb_b_j$$  \n",
    "\n",
    "We have to admit one thing if only the number of the first matrix's columns equals the number of the second matrix's rows, then these two matrixes can multiply.\n"
   ],
   "id": "6d2959e14d6e96c2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T14:15:29.875139Z",
     "start_time": "2024-06-03T14:15:29.870901Z"
    }
   },
   "cell_type": "code",
   "source": [
    "d = np.array([[1,2,3],[4,5,6],[7,8,9]])\n",
    "e = np.array([[10,11,12],[13,14,15],[16,17,18]])\n",
    "print(np.matmul(d, e))"
   ],
   "id": "fe1d83886fbb272e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 84  90  96]\n",
      " [201 216 231]\n",
      " [318 342 366]]\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "##### *2.3.2 Inner Product*\n",
    "  \n",
    "Inner product can be treated as a special matrix multiplication.  \n",
    "\n",
    "For two vectors in Hilbert space $|a>$ and $|b>$, $<a|b>$this means that their inner product. And $<a|$ is defined as $|a>$'s conjugate transpose. This can also be noted as $|a>^†$.  \n",
    "\n",
    "The notation $†$, called \"dagger\", means conjugate transpose.  \n",
    "\n",
    "So you may have another question. What is conjugate transpose? Conjugate transpose means you turn a row vector first into a column vector(vice versa) then take the conjugate of the data inside.  \n",
    "\n",
    "P.S: Conjugate: When we take the conjugate of $a+bi$ it will become $a-bi$  \n",
    "\n",
    "$$\\begin{aligned}<a|b> = (a_1, a_2, a_3,..., a_n)^†\\times(b_1, b_2, b_3,..., b_n) = a_1^*b_1 + a_2^*b_2 + ... + a_n^*b_n\\end{aligned}$$"
   ],
   "id": "5409eb1d4be55db5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T14:15:34.798643Z",
     "start_time": "2024-06-03T14:15:34.792673Z"
    }
   },
   "cell_type": "code",
   "source": [
    "base = np.arange(3)\n",
    "f = base - 1j * base\n",
    "g = base - 2j * base\n",
    "print(\"vector f: \\n\", f)\n",
    "print(\"vector g: \\n\", g)\n",
    "print(\"The conjugate vector f: \\n\", np.conjugate(f))\n",
    "\n",
    "print(\"<f|g>: \\n\", np.inner(np.conjugate(f), g))"
   ],
   "id": "3ee4623eef44d79f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector f: \n",
      " [0.+0.j 1.-1.j 2.-2.j]\n",
      "vector g: \n",
      " [0.+0.j 1.-2.j 2.-4.j]\n",
      "The conjugate vector f: \n",
      " [0.-0.j 1.+1.j 2.+2.j]\n",
      "<f|g>: \n",
      " (15-5j)\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "##### *2.3.3 Outer Product*\n",
    "\n",
    "That's right! We got inner product, so we must have outer product.  \n",
    "\n",
    "$|a><b|$represent outer product of two vectors in Hilbert space.\n",
    "\n",
    "$$\\begin{aligned}|a><b| = (a_1, a_2, a_3,..., a_n)\\times(b_1, b_2, b_3,..., b_n)^† = a_1b_1^* + a_2b_2^* + a_3b_3^* + ... + a_nb_n^*\\end{aligned}$$"
   ],
   "id": "94156e5791fbd880"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T14:15:42.763025Z",
     "start_time": "2024-06-03T14:15:42.758602Z"
    }
   },
   "cell_type": "code",
   "source": "print(\"|f><g|: \\n\", np.outer(f, np.conjugate(g)))",
   "id": "363d50fb3d77965b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|f><g|: \n",
      " [[ 0.+0.j  0.+0.j  0.+0.j]\n",
      " [ 0.-0.j  3.+1.j  6.+2.j]\n",
      " [ 0.-0.j  6.+2.j 12.+4.j]]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "##### *2.3.4 Tensor Product*\n",
    "\n",
    "Finally! We meet the most-most-most important calculation method ------ the tensor product.  \n",
    "\n",
    "We first talk about the vector:\n",
    "\n",
    "$|a>\\otimes|b>$denotes the tensor product of two vectors in Hilbert space. So we can get:\n",
    "$$\\begin{aligned}|a>\\otimes|b> = (a_1b_1, a_1b_2, a_2b_1, a_2b_2)^T\\end{aligned}$$ T means turn row vector to column vector(vice versa)."
   ],
   "id": "f1f36381590df22b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T14:15:53.324868Z",
     "start_time": "2024-06-03T14:15:53.321099Z"
    }
   },
   "cell_type": "code",
   "source": [
    "np.kron(f, g)\n",
    "print(\"|f> tensor |g>: \\n\", np.kron(f, g))"
   ],
   "id": "abf2ba02cc32464f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|f> tensor |g>: \n",
      " [ 0. +0.j  0. +0.j  0. +0.j  0. +0.j -1. -3.j -2. -6.j  0. +0.j -2. -6.j\n",
      " -4.-12.j]\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Then the matrix A and B:\n",
    "\n",
    "$$A\\otimes B = $$\n",
    "$$\\left(\\begin{array}{ccc}\n",
    "a_1_1B & \\ldots  &a_1_nB \\\\\\\\\n",
    "\\vdots & \\ddots & \\vdots \\\\\\\\\n",
    "a_n_1B & \\ldots & a_n_nB\n",
    "\\end{array}\\right)$$"
   ],
   "id": "a3300d3eaa2c7e12"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T14:15:58.391030Z",
     "start_time": "2024-06-03T14:15:58.387332Z"
    }
   },
   "cell_type": "code",
   "source": [
    "np.kron(np.eye(2), np.ones((2, 2)))\n",
    "print(\"A tensor B: \\n\", np.kron(np.eye(2), np.ones((2, 2))))"
   ],
   "id": "b5bcb92e87de9604",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A tensor B: \n",
      " [[1. 1. 0. 0.]\n",
      " [1. 1. 0. 0.]\n",
      " [0. 0. 1. 1.]\n",
      " [0. 0. 1. 1.]]\n"
     ]
    }
   ],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
